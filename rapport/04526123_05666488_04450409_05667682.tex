\documentclass[12pt,letterpaper]{article}
\usepackage{amsmath}
\usepackage{fancyhdr}
\usepackage{graphicx}
\usepackage{alltt}
\usepackage{color}
\usepackage{colortbl}
\usepackage{fullpage}
\usepackage{setspace}
\usepackage{pstricks}
\usepackage{verbatim}
\usepackage{comment}
\usepackage{framed}
\usepackage{listings}
\usepackage{longtable}
\usepackage{pdflscape}
\usepackage{multirow}
\usepackage[config=altsf]{subfig}
\usepackage[utf8]{inputenc}
\usepackage[francais]{babel}
\usepackage[plainpages=false,pdfpagelabels,hypertexnames=false]{hyperref}

%For pdf selection
\usepackage[T1]{fontenc}
\usepackage{lmodern}

%%%%% STYLE %%%%%%%
\topmargin	0in
\topskip	0in
\headheight	0in
\headsep	0in
\parindent	0in
\topsep		0in
\parskip	8pt
\floatsep	0in
%%%%%%%%%%%%%%%%%%%%

%%% SETUP HYPERLINK %%%%%
\hypersetup{
colorlinks 	= true,
linkcolor 	= black}
%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

%%%%%%% COMMANDS %%%%%%%%
\renewcommand{\labelitemi}{$\bullet$}
\newcommand{\unit}[1]{\ \mathrm{#1}}
\newcommand{\degree}{\ensuremath{^\circ}}
%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%% PAGE TITRE %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\thispagestyle{empty}
\begin{center}
	\vspace{20pt}
	\large{\textsc{
		Intelligence artificielle bio-inspirée\\
	}}
	\vspace{20pt}
	\large{\textsc{
		P02
	}}
	\vfill
	\begin{tabular}{ll}
      Simon Mathieu & 04 450 409 \\
      Steven Denis & 05 667 682 \\
      Michael Janelle-Montcalm & 04 526 123 \\
      Martin Provencher &	05 666 488 \\
	\end{tabular}
	\vfill
	Novembre 2009 \\
	\textbf{Université de Sherbrooke}
	\vspace{20pt}
\end{center}
\clearpage
%%%%%%%%%%%%%%%%%%%%% TABLE DES MATIÈRES %%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{spacing}{0.1}
\tableofcontents
\end{spacing}
\clearpage

\section{Introduction}

\section{Analyse des données} % Steven
% Similitudes entre les canaux (redondance entre 1 et 6, on garde 6)
% Valeurs des maxima et minima sont plus grandes lors d'une chute que lors
% d'une non-chute

\section{Hypothèses simplificatrices}

\subsection{Logique floue}

\subsection{Réseau de neurones} % Mike
% Utilisation seulement des max et min permet d'identifier les chutes

\section{Représentation de l'information}

\subsection{Logique floue}

Au niveau de l'algorithme de logique floue, nous avons commencé par éliminer un capteur au complet. Premièrement, ce choix permet de diminuer le coût du système. Deuxièmement, utiliser les trois axes des deux capteurs augmentent de façon drastique le nombre de règles à écrire et alourdi presque inutilement le système. Pour le choix du capteur, nous avons choisit le capteur sous le bras puisqu'en général, il y a de plus grandes variations sur ce capteur.

Pour le traitement des données, nous n'utilisons que deux valeurs par axe de capteur, le maximum et le minimum de l'échantillon de temps. Par la suite, nous utilisons l'équation : $||max|-|min||$. Cette équation permet de déterminer la différence des accélérations positives et négatives. Si cette valeur est petite, elle signifie qu'une personne a réussi à appliquer une force équivalente opposée à la chute pour se rattraper ou aucune chute n'a eu lieu. Donc, il y a 3 entrées à notre algorithme de logique floue.

\subsection{Réseau de neurones} % Steven
% Schéma-bloc du système
% Extraction des caractéristiques (max, min)
% Entrées et sorties (fichiers de données, sorties du script)

\section{Mise en oeuvre}

\subsection{Logique floue}

\begin{figure}
    \centering
    \subfigure[Axe X]{
        \label{fig:f_xi}
        \fbox{\includegraphics[scale=0.2]{images/f_sensor4.png}}}
    \quad
    \subfigure[Axe Y]{
        \label{fig:f_yi}
        \fbox{\includegraphics[scale=0.2]{images/f_sensor5.png}}}

    \subfigure[Axe Z]{
        \label{fig:f_zi}
        \fbox{\includegraphics[scale=0.2]{images/f_sensor6.png}}}

    \caption{Équations entrées de l'algorithme de logique floue}
    \label{fig:f_input}
\end{figure}

\begin{figure}
\centering
\includegraphics[scale=0.2]{images/f_chute.png}
\caption{Équation de sortie (chute) de l'algorithme de logique floue}
\label{fig:f_output}
\end{figure}

\begin{figure}
    \centering
    \subfigure[Axe X : petit]{
        \label{fig:f_x_petit}
        \includegraphics[scale=0.35]{images/f_s4_petit.png}}
    \quad
    \subfigure[Axe X : moyen]{
        \label{fig:f_x_moyen}
        \includegraphics[scale=0.35]{images/f_s4_moyen.png}}
    \quad
    \subfigure[Axe X : grand]{
        \label{fig:f_x_grand}
        \includegraphics[scale=0.35]{images/f_s4_grand.png}}

    \caption{Règles de l'algorithme de logique floue}
    \label{fig:f_rule}
\end{figure}

Pour implémenter cette solution, il a fallu tout d'abord déterminer la fuzzification des variables d'entrées. Ces équations
se retrouve à la figure \ref{fig:f_input}. Les valeurs varient entre 0 et 100 puisqu'après analyse des résultats, nous avons conclu que les valeurs obtenues seront toujours dans cet intervalle. Nous avons choisi d'utiliser trois fonctions d'appartenance par entrée puisque cela représentait bien notre domaine. Par la suite, nous avons déterminé la défuzzification du système avec quatre fonctions d'appartenance affichées à la figure \ref{fig:f_output}. Nous avons choisit plus de fonctions d'appartenance pour la sortie de façon à être plus précis lors de l'écriture des règles. Finalement, nous avons défini nos règles tel que présenté à la figure \ref{fig:f_rule}. Nous avons choisit de garder les combinaisons de variables standards : le AND pour combiner les entrées, le OR pour combiner les sortie et le centroïde pour avoir la valeur finale du système.

Une fois l'algorithme de logique floue configuré, il faut identifier à partir de quelle valeur de sortie nous considérons l'entrée comme étant une chute. Pour se faire, nous avons testé plusieurs valeurs de seuil autour de 0.5 avec tous les échantillons en entrée pour trouver un seuil idéal à 0.42.

\subsection{Réseau de neurones} % Mike
% Données d'entraînement (sujet 5)
% Description de l'évolution du réseau (époques)
% Paramètres d'entraînement (momentum, learning rate)
% Ne converge pas toujours
% – Loi d’apprentissage, nombre d’unités cachées, nombre d’unités de sortie a expérimenter ;
% – Critères d’entraînement et d’évaluation ;
% – Création des ensembles d’entraînement et de test en lien avec l’apprentissage ;
% – Critère de classification et de reconnaissance.

\subsection{Algorithme génétique}

Originalement, nous voulions utiliser le nombre de piques dans le graphique de la dérivé pour détecter les chutes.
Si le graphique d'un capteur contenait un pique, il s'agit probablement d'une chute, si il en contient aucun, il
ne s'agît pas d'une chute. S’il en contient plusieurs, il s'agit d'une récupération de chute.

Éventuellement, cette solution fut rejetée en faveur d'une solution offrant de meilleurs résultats, mais nous
présentons tout de même l'implémentation et les conclusions tiré de cette expérience.

Les figures \ref{fig:chute} et \ref{fig:nonchute} montre la différence entre une chute et une récupération de chute.

\begin{figure}[htp]
\centering
\includegraphics{images/piques_chute.png}
\caption{Nombre de piques pour une chute}
\label{fig:chute}
\end{figure}

\begin{figure}[htp]
\centering
\includegraphics{images/piques_nonchute.png}
\caption{Nombre de piques pour une non-chute}
\label{fig:nonchute}
\end{figure}


Pour détecter un pique, nous utilisions une librairie matlab trouvée sur internet. La fonction de détection de pique
possède 4 paramètres permettant de contrôler, quels points du graphique sont détectés comme étant des piques.

Comme ces paramètres peuvent prendrent une très grande quantité de valeurs, il s'agissait d'un cas intéressant ou utiliser
un algorithme génétique pour trouver des valeurs optimisées. Il est à noter qu'un algorithme génétique ne retourne pas
nécessairement la solution optimale, mais bien une solution possible.

La première étape de la mise en oeuvre fut de manuellement se créer des données d'entrainement. Nous avons donc
observé les graphiques de la dérivé de certains des capteurs et avons estimé le nombre de piques.

Armée de ces données, nous avons ensuite défini une fonction de pertinence qui permet de calculer la distance à laquelle
une donnée est de la valeur réelle.

Nous avons ensuite défini une population d'individu qui se composait d'un ensemble de valeurs représente les paramètres de la
fonction qui trouve les piques.

La prochaine étape consiste a faire reproduire et muter les individus de notre population pour produire la prochaine génération.
Lors de la reproduction et de la mutation, il existe une probabilité que des gènes soient transférés d'un parent à l'enfant et une
probabilité qu'un gène mute. On peut optimiser la vitesse de convergence de l'algorithme en modifiants ces probabilités. Après
expérimentation, nous avons conclu qu'il était mieux de conserver les individus les plus adaptés d'une génération dans la prochaine.
Nous gardons donc les cinq individus les mieux adaptés.

Le choix des individus qui se reproduisent est fait à l'aide d'une fonction aléatoire pondéré de façon à ce que les individus possédant
de meilleurs gènes aient une meilleure probabilité de se reproduire.

Le pseudo-code de notre algorithme est:

\begin{verbatim}
pop = InitPopulation

FOR n generation
  fitenesses = CalculateFitness pop
  breeders = SelectBreeders pop
  pop = Reproduce breeders
  pop = Mutate pop

\end{verbatim}


\section{Évaluation des performances}

\subsection{Logique floue}

Tout d'abord, notre algorithme de logique a un taux de détection de 88.5\% : 92\% de reconnaissance de chute et 85\% de reconnaissance de non-chute. Nous considérons cette valeur assez élevée pour considérer cette technique satisfaisante. En plus, l'algorithme prend, pour s'exécuter, entre 3 et 24 millisecondes avec une moyenne à 9 millisecondes. Donc, nous pourrions facilement implémenter un système de détection de chute à la seconde prêt, en temps réel pour un humain.

En guise de comparaison, nous avons également essayé l'algorithme de logique floue avec seulement les axes Y et Z du capteur 2. Cette implémentation nous donne, à un seuil de 0.40, 83.5\% de détection : 79\% de reconnaissance de chute et 88\% de reconnaissance de non-chute. En temps de calcul, cette solution prend entre 3 et 24 millisecondes avec une moyenne à 9 millisecondes. Donc, puisque les données sont déjà disponibles sans augmentation des coûts en argent ou en temps, il est plus avantageux d'utiliser le système avec les 3 axes.

\subsection{Réseau de neurones} % Mike
% Taux d'identification (avec explications des variations selon les paramètres)
% Performance avec les données d'entraînement, puis les données de test
% Différence des résultats selon le nombre d'unités cachées

\subsection{Algorithme génétique}

Dans notre cas, l'algorithme générique nous a permis de converger plutôt rapidement vers une solution suffisamment optimale.

Malheureusement, trouver le nombre de piques dans une fonction n'est pas un problème simple. La librairie que nous utilisions
s'est avérée insuffisante pour détecter les pics correctement dans les données que nous avions.

Nous avons manuellement ajusté les paramètres de l'algorithme génétique. À chaque itération, nous modifions les paramètres pour
améliorer les résultats. Les résultats étaient obtenus à l'aide de la fonction de la fonction de pertinence.

\begin{table}[h]
  \begin{center}
    \begin{tabular} {|l|l|}
        \hline
        Nombre de génération & 60 \\
        \hline
        Nombre de chromosones & 250 \\
        \hline
        Probabilité de crossover & 0.8 \\
        \hline
        Probabilité de mutation & 0.02 \\
        \hline
    \end{tabular}
    \caption{Paramètres de l'algorithme génétique}
  \end{center}
\end{table}

Nous avons aussi modifié la fonction de pertinence pour quel attribut une plus grande valeur aux graphiques ayant plus qu’un pic.
Nous avons dû faire cette optimisation, car trop de graphiques avaient un seul sommet, ce qui permettait a notre algorithme d'avoir une bonne
performance en identifiant 1 sommet pour tous les graphiques.

Les résultats obtenus sont affichés dans la table \ref{tab:genparam}.

\begin{table}[h]
  \begin{center}
    \begin{tabular} {|l|l|}
        \hline
        \bf{Paramètre} & \bf{Valeur} \\
        \hline
        SlopeThreshold & 2.1067 \\
        \hline
        AmpThreshold & 3.2950 \\
        \hline
        SmoothWidth & 1.2083 \\
        \hline
        PeakGroup & 24.1062 \\
        \hline
    \end{tabular}
    \caption{Paramètres trouvés à l'aide de l'algorithme génétique}
    \label{tab:genparam}
  \end{center}
\end{table}

Avec ces données, nous obtenons une pertinence de 62.3438.

Au niveau du temps d'exécution, l'exécution d'une fonction génétique nécessite beaucoup de ressources. Par contre, il est à noter que
cette quantité de travail est bien moindre que celle nécessaire avec un algorithme plus conventionnel. Aussi, pour notre application, nous n'avons
qu'a rouler une fois l'algorithme pour obtenir les paramètres optimisés. Une fois ces paramètres obtenus, nous pouvons les réutiliser à chaque exécution.

\section{Observations et perspectives futures}

\end{document}
